# About
Creating a Seq2Seq transformer model with attention mechanisms for machine translation.

# Data Collection
- Collected and downloaded English-French sentence pairs from the [Tatoeba](https://tatoeba.org/en/downloads) website.

# Data Pre-processing
- Cleaned and tokenized the text data.
- Split the data into training and validation sets.

# Model Creation and Training
- Implemented a Transformer model using PyTorch.
- Trained the model on the bilingual sentence pairs.

# Evaluation
- Evaluated the translation quality using the BLEU score.